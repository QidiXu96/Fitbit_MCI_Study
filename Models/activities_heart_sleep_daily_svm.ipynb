{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import shap\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_csv('activities_final.txt', sep='\\t')\n",
    "activities = activities.drop(['activity_Run', 'activity_Walk', 'race', 'gender', 'activeScore', 'caloriesBMR'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_days = pd.read_csv('included_days.txt', sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.merge(activities, valid_days, left_on=['User', 'Date'], right_on=['User', 'Day'])\n",
    "activity = activity.drop(['Day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep = pd.read_csv('sleep_final.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sleep(row):\n",
    "    main_sleep_conditions = all(pd.isna(row[key]) for key in ['asleep_count', 'asleep_minutes', \n",
    "                                                             'awake_count', 'awake_minutes',\n",
    "                                                             'restless_minutes', 'restless_count'])\n",
    "    nap_conditions = all(pd.isna(row[key]) for key in ['deep_count', 'deep_minutes', 'deep_thirtyDayAvgMinutes', \n",
    "                                                      'light_count', 'light_minutes', 'light_thirtyDayAvgMinutes',\n",
    "                                                      'rem_count', 'rem_minutes', 'rem_thirtyDayAvgMinutes',\n",
    "                                                      'wake_count', 'wake_minutes', 'wake_thirtyDayAvgMinutes'])\n",
    "    if nap_conditions:\n",
    "        return \"Nap\"\n",
    "    elif main_sleep_conditions:\n",
    "        return \"Main Sleep\"\n",
    "    else:\n",
    "        return \"Inconclusive\"\n",
    "\n",
    "sleep['classification'] = sleep.apply(classify_sleep, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainsleep = sleep[sleep['classification']=='Main Sleep']\n",
    "mainsleep = mainsleep.drop(['startTime', 'endTime', 'gender', 'race',\n",
    "                'duration', 'isMainSleep', 'classification'], axis=1) \n",
    "mainsleep = mainsleep.dropna(axis = 1) #remove features related with naps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities + Heart rate + MainSleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = ['label', 'User', 'age', 'Date']\n",
    "df = pd.merge(activity, mainsleep, on=common_features, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date', 'age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['label'])  \n",
    "y = df['label']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "cols = X.columns[X.columns != 'User']\n",
    "X[cols] = scaler.fit_transform(X[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "X['User'] = X['User'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396603291e284f02acb9424740047e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1b25923b50427ca9999c0e58b9b043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065a3cb3f05541caab36854d2c9ee3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff42109ffb04bc488aef5aee610b33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7f18f8cc27448683d34947fd182b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "models = []\n",
    "auc_scores = []\n",
    "feature_occurrences = {} \n",
    "shaps = []\n",
    "\n",
    "for i, (train_outer_ix, test_outer_ix) in enumerate(group_kfold.split(X, y, groups=X['User'])):\n",
    "    X_train, y_train = X.iloc[train_outer_ix].drop(columns='User'), y.iloc[train_outer_ix]\n",
    "    X_test, y_test = X.iloc[test_outer_ix].drop(columns='User'), y.iloc[test_outer_ix]\n",
    "    \n",
    "    #model\n",
    "    model = SVC(probability=True, kernel='linear', random_state=7) \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #SHAP in training\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, X_train)\n",
    "    shap_values = explainer.shap_values(X_train) # 3D\n",
    "    averaged_shap_values = np.mean(np.abs(shap_values), axis=0) #2D\n",
    "    shap_importance = np.mean(averaged_shap_values, axis=0) #1D\n",
    "    shaps.extend(shap_importance)\n",
    "    important_features = np.array(X_train.columns)[shap_importance > alpha]\n",
    "\n",
    "    #count\n",
    "    for feature in important_features:\n",
    "        if feature in feature_occurrences:\n",
    "            feature_occurrences[feature] += 1\n",
    "        else:\n",
    "            feature_occurrences[feature] = 1\n",
    "\n",
    "    #test with selected features\n",
    "    X_train_selected = X_train[important_features]\n",
    "    X_test_selected = X_test[important_features]\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    yhat_probs = model.predict_proba(X_test_selected)[:, 1] \n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, yhat_probs)\n",
    "        auc_scores.append(auc)\n",
    "    except ValueError:\n",
    "        print(\"Skipping AUC calculation for this fold due to single class in y_true.\")\n",
    "        auc_scores.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean AUC of the 5 folds is  0.5279252717624345\n",
      "The std AUC of the 5 folds is  0.20340585129616828\n"
     ]
    }
   ],
   "source": [
    "print('The mean AUC of the 5 folds is ', np.nanmean(auc_scores))\n",
    "print('The std AUC of the 5 folds is ', np.nanstd(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_selected_features = [feature for feature, count in feature_occurrences.items() if count >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.drop('User', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524, 13)\n",
      "(524,)\n"
     ]
    }
   ],
   "source": [
    "X_filtered = X[final_selected_features]\n",
    "print(X_filtered.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['caloriesOut', 'lightlyActiveMinutes', 'restingHeartRate',\n",
       "       'heartRateZone_Out_ofRange_caloriesOut',\n",
       "       'heartRateZone_Out_ofRange_minutes', 'light_thirtyDayAvgMinutes',\n",
       "       'marginalCalories', 'activity_veryActive',\n",
       "       'heartRateZone_Fat_Burn_caloriesOut', 'heartRateZone_Fat_Burn_minutes',\n",
       "       'heartRateZone_Cardio_caloriesOut', 'heartRateZone_Cardio_minutes',\n",
       "       'rem_thirtyDayAvgMinutes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = X_filtered.copy()\n",
    "X_filtered['User'] = df['User']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "SHAP_values_per_fold = []\n",
    "all_X_tests = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model\n",
    "    model = CatBoostClassifier(iterations=200, learning_rate=0.01, depth=8, l2_leaf_reg=3, random_seed=7, \n",
    "                               loss_function='Logloss')\n",
    "    model.fit(X_train, y_train, cat_features=[], verbose=0)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    # SHAP\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    SHAP_values_per_fold.append(shap_values)\n",
    "    all_X_tests.append(X_test)\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority voting: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority voting:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = xgb.XGBClassifier(n_estimators=400, learning_rate=0.01, max_depth=8, \n",
    "                              random_state=7, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    model.fit(X_train, y_train, verbose=0)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.775\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=7) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.8\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "all_pred_labels = []\n",
    "all_pred_probs = []\n",
    "all_true_labels = []\n",
    "all_users = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = SVC(probability=True, kernel='rbf', random_state=7) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    all_pred_labels.extend(predicted_labels.values())\n",
    "    all_pred_probs.extend(predicted_probs.values())\n",
    "    all_true_labels.extend(true_labels.values())\n",
    "    all_users.extend(true_labels.keys())\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = LogisticRegression(random_state=7, max_iter=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.5999999999999999\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities + Heart + Naps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "naps = sleep[sleep['classification']=='Nap']\n",
    "naps = naps.drop(['startTime', 'endTime', 'duration', 'isMainSleep', 'classification', 'gender', 'race'], axis=1) \n",
    "naps = naps.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = ['label', 'User', 'age', 'Date']\n",
    "df = pd.merge(activity, naps, on=common_features, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date', 'age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['label']) \n",
    "y = df['label']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "cols = X.columns[X.columns != 'User']\n",
    "X[cols] = scaler.fit_transform(X[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "X['User'] = X['User'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6946e72ad846424da976c70a929d7fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AUC calculation for this fold due to single class in y_true.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d575ba329f7d480eb048763da4967eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c1849e1db945bba5bad4908048f978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a371ab2379304bee9f9d13d1318e49f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1aa0c9e76e846a78e2f8ef41a93dbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping AUC calculation for this fold due to single class in y_true.\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "models = []\n",
    "auc_scores = []\n",
    "feature_occurrences = {} \n",
    "shaps = []\n",
    "\n",
    "for i, (train_outer_ix, test_outer_ix) in enumerate(group_kfold.split(X, y, groups=X['User'])):\n",
    "    X_train, y_train = X.iloc[train_outer_ix].drop(columns='User'), y.iloc[train_outer_ix]\n",
    "    X_test, y_test = X.iloc[test_outer_ix].drop(columns='User'), y.iloc[test_outer_ix]\n",
    "    \n",
    "    #model\n",
    "    model = SVC(probability=True, kernel='linear', random_state=7) \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #SHAP in training\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, X_train)\n",
    "    shap_values = explainer.shap_values(X_train) # 3D\n",
    "    averaged_shap_values = np.mean(np.abs(shap_values), axis=0) #2D\n",
    "    shap_importance = np.mean(averaged_shap_values, axis=0) #1D\n",
    "    shaps.extend(shap_importance)\n",
    "    important_features = np.array(X_train.columns)[shap_importance > alpha]\n",
    "\n",
    "    #count\n",
    "    for feature in important_features:\n",
    "        if feature in feature_occurrences:\n",
    "            feature_occurrences[feature] += 1\n",
    "        else:\n",
    "            feature_occurrences[feature] = 1\n",
    "\n",
    "    #test with selected features\n",
    "    X_train_selected = X_train[important_features]\n",
    "    X_test_selected = X_test[important_features]\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    yhat_probs = model.predict_proba(X_test_selected)[:, 1] \n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, yhat_probs)\n",
    "        auc_scores.append(auc)\n",
    "    except ValueError:\n",
    "        print(\"Skipping AUC calculation for this fold due to single class in y_true.\")\n",
    "        auc_scores.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean AUC of the 5 folds is  0.8882225553889721\n",
      "The std AUC of the 5 folds is  0.09484930284162234\n"
     ]
    }
   ],
   "source": [
    "print('The mean AUC of the 5 folds is ', np.nanmean(auc_scores))\n",
    "print('The std AUC of the 5 folds is ', np.nanstd(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_selected_features = [feature for feature, count in feature_occurrences.items() if count >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('User', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 13)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "X_filtered = X[final_selected_features]\n",
    "print(X_filtered.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['caloriesOut', 'lightlyActiveMinutes', 'sedentaryMinutes', 'steps',\n",
       "       'veryActiveMinutes', 'heartRateZone_Out_ofRange_caloriesOut',\n",
       "       'heartRateZone_Out_ofRange_minutes',\n",
       "       'heartRateZone_Fat_Burn_caloriesOut', 'heartRateZone_Cardio_minutes',\n",
       "       'restingHeartRate', 'heartRateZone_Out_ofRange_min',\n",
       "       'heartRateZone_Fat_Burn_max', 'totalTimeInBed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = X_filtered.copy()\n",
    "X_filtered['User'] = df['User']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in fold 0. Skipping AUC calculation.\n",
      "Only one class present in fold 4. Skipping AUC calculation.\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model\n",
    "    model = CatBoostClassifier(iterations=10, learning_rate=0.01, depth=8, l2_leaf_reg=3, random_seed=6, \n",
    "                               loss_function='Logloss')\n",
    "    model.fit(X_train, y_train, cat_features=[], verbose=0)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority voting: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority voting:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only one class present in fold 1. Skipping AUC calculation.\n",
      "Warning: Only one class present in fold 5. Skipping AUC calculation.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.01, max_depth=8, \n",
    "                              random_state=9, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    model.fit(X_train, y_train, verbose=10)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Warning: Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.5\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in fold 1. Skipping AUC calculation.\n",
      "Only one class present in fold 5. Skipping AUC calculation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model\n",
    "    model = RandomForestClassifier(n_estimators=10, max_depth=8, random_state=9)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in fold 1. Skipping AUC calculation.\n",
      "Only one class present in fold 5. Skipping AUC calculation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = SVC(probability=True, kernel='linear', random_state=7)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.75\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in fold 1. Skipping AUC calculation.\n",
      "Only one class present in fold 5. Skipping AUC calculation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = LogisticRegression(random_state=7, max_iter=200)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "\n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.75\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in fold 1. Skipping AUC calculation.\n",
      "Only one class present in fold 5. Skipping AUC calculation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['User'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='User'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='User'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['User']\n",
    "    \n",
    "    # model   \n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.5\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
