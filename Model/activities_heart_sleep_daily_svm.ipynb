{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import shap\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from collections import defaultdict\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = pd.read_csv('activity.txt', sep='\\t') \n",
    "activity = activity.drop(['gender', 'race', 'caloriesBMR'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep = pd.read_csv('sleep.txt', sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into main sleep and naps\n",
    "def classify_sleep(row):\n",
    "    main_sleep_conditions = all(pd.isna(row[key]) for key in ['asleep_count', 'asleep_minutes', \n",
    "                                                             'awake_count', 'awake_minutes',\n",
    "                                                             'restless_minutes', 'restless_count'])\n",
    "    nap_conditions = all(pd.isna(row[key]) for key in ['deep_count', 'deep_minutes', 'deep_thirtyDayAvgMinutes', \n",
    "                                                      'light_count', 'light_minutes', 'light_thirtyDayAvgMinutes',\n",
    "                                                      'rem_count', 'rem_minutes', 'rem_thirtyDayAvgMinutes',\n",
    "                                                      'wake_count', 'wake_minutes', 'wake_thirtyDayAvgMinutes'])\n",
    "    if nap_conditions:\n",
    "        return \"Nap\"\n",
    "    elif main_sleep_conditions:\n",
    "        return \"Main Sleep\"\n",
    "    else:\n",
    "        return \"Inconclusive\" \n",
    "\n",
    "sleep['classification'] = sleep.apply(classify_sleep, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainsleep = sleep[sleep['classification']=='Main Sleep']\n",
    "mainsleep = mainsleep.drop(['isMainSleep', 'classification',\n",
    "                'gender', 'race'], axis=1) \n",
    "mainsleep = mainsleep.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activity + heart rate + main sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = ['label', 'participant', 'age', 'date']\n",
    "df = pd.merge(activity, mainsleep, on=common_features, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['date', 'age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['label'])  \n",
    "y = df['label']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "cols = X.columns[X.columns != 'participant']\n",
    "X[cols] = scaler.fit_transform(X[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "X['participant'] = X['participant'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8960e9ef95945199a8a5e5ece090321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/461 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bf151b62b7448b8f04b2c3777d1b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f718b4f04cda4f25b4b960c456e3b861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afe88546aa74787a1c27f81a8d97547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937726bc294f49b0a67d28823a402950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "models = []\n",
    "auc_scores = []\n",
    "feature_occurrences = {} \n",
    "shaps = []\n",
    "\n",
    "for i, (train_outer_ix, test_outer_ix) in enumerate(group_kfold.split(X, y, groups=X['participant'])):\n",
    "    X_train, y_train = X.iloc[train_outer_ix].drop(columns='participant'), y.iloc[train_outer_ix]\n",
    "    X_test, y_test = X.iloc[test_outer_ix].drop(columns='participant'), y.iloc[test_outer_ix]\n",
    "    \n",
    "    #model\n",
    "    model = SVC(probability=True, kernel='linear', random_state=7) \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #SHAP in training\n",
    "    explainer = shap.KernelExplainer(model.predict_proba, X_train)\n",
    "    shap_values = explainer.shap_values(X_train) # 3D\n",
    "    averaged_shap_values = np.mean(np.abs(shap_values), axis=0) #2D\n",
    "    shap_importance = np.mean(averaged_shap_values, axis=0) #1D\n",
    "    shaps.extend(shap_importance)\n",
    "    important_features = np.array(X_train.columns)[shap_importance > alpha]\n",
    "\n",
    "    #count\n",
    "    for feature in important_features:\n",
    "        if feature in feature_occurrences:\n",
    "            feature_occurrences[feature] += 1\n",
    "        else:\n",
    "            feature_occurrences[feature] = 1\n",
    "\n",
    "    #test with selected features\n",
    "    X_train_selected = X_train[important_features]\n",
    "    X_test_selected = X_test[important_features]\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    yhat_probs = model.predict_proba(X_test_selected)[:, 1] \n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, yhat_probs)\n",
    "        auc_scores.append(auc)\n",
    "    except ValueError:\n",
    "        print(\"Skipping AUC calculation for this fold due to single class in y_true.\")\n",
    "        auc_scores.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean AUC of the 5 folds is  0.4106970158766082\n",
      "The std AUC of the 5 folds is  0.1419256225781693\n"
     ]
    }
   ],
   "source": [
    "print('The mean AUC of the 5 folds is ', np.nanmean(auc_scores))\n",
    "print('The std AUC of the 5 folds is ', np.nanstd(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_selected_features = [feature for feature, count in feature_occurrences.items() if count >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('participant', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 15)\n",
      "(570,)\n"
     ]
    }
   ],
   "source": [
    "X_filtered = X[final_selected_features]\n",
    "print(X_filtered.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = X_filtered.copy()\n",
    "X_filtered['participant'] = df['participant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['participant'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "SHAP_values_per_fold = []\n",
    "all_X_tests = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='participant'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='participant'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['participant']\n",
    "    \n",
    "    # model\n",
    "    model = CatBoostClassifier(iterations=300, learning_rate=0.01, depth=8, l2_leaf_reg=3, random_seed=7, \n",
    "                               loss_function='Logloss')\n",
    "    model.fit(X_train, y_train, cat_features=[], verbose=0)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority voting: 0.5833333333333333\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority voting:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['participant'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='participant'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='participant'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['participant']\n",
    "    \n",
    "    # model   \n",
    "    model = xgb.XGBClassifier(n_estimators=400, learning_rate=0.01, max_depth=8, \n",
    "                              random_state=7, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    model.fit(X_train, y_train, verbose=0)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['participant'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='participant'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='participant'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['participant']\n",
    "    \n",
    "    # model\n",
    "    model = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=7) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['participant'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='participant'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='participant'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['participant']\n",
    "    \n",
    "    # model   \n",
    "    model = SVC(probability=True, kernel='linear', random_state=7) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.8666666666666666\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['participant'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='participant'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='participant'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['participant']\n",
    "    \n",
    "    # model   \n",
    "    model = LogisticRegression(random_state=7, max_iter=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    predicted_labels = {user: 1 if prob >= 0.5 else 0 for user, prob in predicted_probs.items()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "splits = group_kfold.split(X_filtered, y, groups=X_filtered['participant'])\n",
    "\n",
    "models = []\n",
    "auc_per_fold = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(splits, start=1):\n",
    "    X_train, y_train = X_filtered.iloc[train_idx].drop(columns='participant'), y.iloc[train_idx]\n",
    "    X_test, y_test = X_filtered.iloc[test_idx].drop(columns='participant'), y.iloc[test_idx]\n",
    "    groups_test = X_filtered.iloc[test_idx]['participant']\n",
    "    \n",
    "    # model   \n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # test\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # initialization\n",
    "    positive_predictions = defaultdict(int)\n",
    "    total_predictions = defaultdict(int)\n",
    "    \n",
    "    for i, group in enumerate(groups_test):\n",
    "        if yhat[i] == 1:  \n",
    "            positive_predictions[group] += 1\n",
    "        total_predictions[group] += 1\n",
    "    \n",
    "    # calculate the fraction of days predicted as positive for each user\n",
    "    predicted_probs = {user: positive_predictions[user] / total_predictions[user] for user in groups_test.unique()}\n",
    "    \n",
    "    # extract the true labels for each user\n",
    "    true_labels = {user: y_test[groups_test == user].iloc[0] for user in groups_test.unique()}\n",
    "    \n",
    "    # auc\n",
    "    if len(set(true_labels.values())) > 1:\n",
    "        auc = roc_auc_score(list(true_labels.values()), list(predicted_probs.values()))\n",
    "        auc_per_fold.append(auc)\n",
    "    else:\n",
    "        print(f\"Only one class present in fold {fold_num}. Skipping AUC calculation.\")\n",
    "        auc_per_fold.append(float('nan'))  \n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC using majority vote: 0.5499999999999999\n"
     ]
    }
   ],
   "source": [
    "mean_auc = np.nanmean(auc_per_fold)\n",
    "print(\"Mean AUC using majority vote:\", mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python-3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
